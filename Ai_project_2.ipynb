{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0Xh9YAAN3TpP",
      "metadata": {
        "id": "0Xh9YAAN3TpP"
      },
      "source": [
        "# Phase 1: training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f578d97",
      "metadata": {
        "id": "4f578d97"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "\n",
        "# Create the Taxi environment\n",
        "streets = gym.make(\"Taxi-v3\").env\n",
        "streets.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e70cde28",
      "metadata": {
        "id": "e70cde28"
      },
      "outputs": [],
      "source": [
        "q_table = np.zeros([streets.observation_space.n, streets.action_space.n])  # 500 x 6\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.1\n",
        "discount_factor = 0.5\n",
        "exploration = 0.1\n",
        "epochs_list = [1000, 5000, 10000]\n",
        "\n",
        "# Function to train the model for the given number of epochs\n",
        "def train_model(epochs):\n",
        "    rewards = []\n",
        "    steps = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        state = streets.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        total_steps = 0\n",
        "\n",
        "        while not done:\n",
        "            random_value = random.uniform(0, 1)\n",
        "            if random_value < exploration:\n",
        "                action = streets.action_space.sample()  # Explore a random action\n",
        "            else:\n",
        "                action = np.argmax(q_table[state])  # Return the action with the highest q-value\n",
        "\n",
        "            next_state, reward, done, _ = streets.step(action)  # Perform the action\n",
        "\n",
        "            prev_q = q_table[state, action]\n",
        "            next_max_q = np.max(q_table[next_state])\n",
        "            new_q = (1 - learning_rate) * prev_q + learning_rate * (reward + discount_factor * next_max_q)\n",
        "            q_table[state, action] = new_q\n",
        "\n",
        "            total_reward += reward\n",
        "            total_steps += 1\n",
        "            state = next_state\n",
        "\n",
        "        rewards.append(total_reward)\n",
        "        steps.append(total_steps)\n",
        "    return rewards, steps\n",
        "\n",
        "\n",
        "# Function to evaluate the policy for a given number of trips\n",
        "def evaluate_policy(trips):\n",
        "    trip_lengths = []\n",
        "\n",
        "    for trip in range(1, trips + 1):\n",
        "        state = streets.reset()\n",
        "        done = False\n",
        "        trip_length = 0\n",
        "\n",
        "        while not done and trip_length < 25:\n",
        "            action = np.argmax(q_table[state])\n",
        "            next_state, reward, done, _ = streets.step(action)\n",
        "            clear_output(wait=True)\n",
        "            print(\"Trip number \" + str(trip) + \" Step \" + str(trip_length))\n",
        "            print(streets.render(mode='ansi'))\n",
        "            sleep(.2)\n",
        "            state = next_state\n",
        "            trip_length += 1\n",
        "\n",
        "        trip_lengths.append(trip_length)\n",
        "        sleep(.2)\n",
        "\n",
        "    avg_trip_length = sum(trip_lengths) / trips\n",
        "    return avg_trip_length\n",
        "\n",
        "\n",
        "# Train and evaluate the model for different epoch settings\n",
        "for epochs in epochs_list:\n",
        "    print(\"\\nTraining for\", epochs, \"epochs:\")\n",
        "    rewards, steps = train_model(epochs)\n",
        "\n",
        "    # Print rewards and steps for each epoch\n",
        "    print(\"Epoch\\tReward\\tSteps\")\n",
        "    for i in range(epochs):\n",
        "        print(i, \"\\t\", rewards[i], \"\\t\", steps[i])\n",
        "\n",
        "    avg_trip_length = evaluate_policy(10)\n",
        "    print(\"Average Trip Length ({} epochs):\".format(epochs), avg_trip_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zoQ1naAI3sID",
      "metadata": {
        "id": "zoQ1naAI3sID"
      },
      "source": [
        "# Phase 2: Testing and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64ef9e37",
      "metadata": {
        "id": "64ef9e37"
      },
      "outputs": [],
      "source": [
        "q_table = np.zeros([streets.observation_space.n, streets.action_space.n])  # 500 x 6\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.1\n",
        "discount_factors = [0.3, 0.5, 0.7]  # Different discount factors to compare\n",
        "epochs = 10000\n",
        "\n",
        "# Function to train the model for the given number of epochs and discount factor\n",
        "def train_model(epochs, discount_factor):\n",
        "    rewards = []\n",
        "    steps = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        state = streets.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        total_steps = 0\n",
        "\n",
        "        while not done:\n",
        "            random_value = random.uniform(0, 1)\n",
        "            if random_value < exploration:\n",
        "                action = streets.action_space.sample()  # Explore a random action\n",
        "            else:\n",
        "                action = np.argmax(q_table[state])  # Return the action with the highest q-value\n",
        "\n",
        "            next_state, reward, done, _ = streets.step(action)  # Perform the action\n",
        "\n",
        "            prev_q = q_table[state, action]\n",
        "            next_max_q = np.max(q_table[next_state])\n",
        "            new_q = (1 - learning_rate) * prev_q + learning_rate * (reward + discount_factor * next_max_q)\n",
        "            q_table[state, action] = new_q\n",
        "\n",
        "            total_reward += reward\n",
        "            total_steps += 1\n",
        "            state = next_state\n",
        "\n",
        "        rewards.append(total_reward)\n",
        "        steps.append(total_steps)\n",
        "    return rewards, steps\n",
        "\n",
        "\n",
        "# Function to evaluate the policy for a given number of trips\n",
        "def evaluate_policy(trips):\n",
        "    trip_lengths = []\n",
        "    trip_rewards = []\n",
        "\n",
        "    for trip in range(1, trips + 1):\n",
        "        state = streets.reset()\n",
        "        done = False\n",
        "        trip_length = 0\n",
        "        trip_reward = 0\n",
        "\n",
        "        while not done and trip_length < 25:\n",
        "            action = np.argmax(q_table[state])\n",
        "            next_state, reward, done, _ = streets.step(action)\n",
        "            state = next_state\n",
        "            trip_length += 1\n",
        "            trip_reward += reward\n",
        "\n",
        "        trip_lengths.append(trip_length)\n",
        "        trip_rewards.append(trip_reward)\n",
        "\n",
        "    avg_trip_length = sum(trip_lengths) / trips\n",
        "    avg_trip_reward = sum(trip_rewards) / trips\n",
        "    return avg_trip_length, avg_trip_reward\n",
        "\n",
        "\n",
        "# Train and evaluate the model for different discount factors\n",
        "results = []\n",
        "\n",
        "for discount_factor in discount_factors:\n",
        "    print(\"\\nTraining for\", epochs, \"epochs with discount factor =\", discount_factor)\n",
        "    rewards, steps = train_model(epochs, discount_factor)\n",
        "\n",
        "    # Print rewards and steps for each epoch\n",
        "    print(\"Epoch\\tReward\\tSteps\")\n",
        "    for i in range(epochs):\n",
        "        print(i, \"\\t\", rewards[i], \"\\t\", steps[i])\n",
        "\n",
        "    avg_trip_length, avg_trip_reward = evaluate_policy(10)\n",
        "    print(\"Average Trip Length ({} epochs):\".format(epochs), avg_trip_length)\n",
        "    print(\"Average Trip Reward ({} epochs):\".format(epochs), avg_trip_reward)\n",
        "    \n",
        "    results.append((discount_factor, avg_trip_length, avg_trip_reward))\n",
        "\n",
        "# Print the results for each discount factor\n",
        "print(\"\\nResults:\")\n",
        "print(\"Discount Factor\\tAverage Trip Length\\tAverage Trip Reward\")\n",
        "for result in results:\n",
        "    print(result[0], \"\\t\\t\", result[1], \"\\t\\t\\t\", result[2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IqymZayh7jca",
      "metadata": {
        "id": "IqymZayh7jca"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
